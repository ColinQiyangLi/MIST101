{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIST101 Pratical 2: Introduction to Tensorflow (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first tutorial of MIST101. The goal of this tutorial is to show how to use Tensorflow to train and evaluate a simple neural network for handwritten digit classification using the MNIST data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data # For tutorial purpose, we directly get the data set from tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import mnist   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data and save them into a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data_sets = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize what the data look like, we can randomly pick an image input and label from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random pick a image-label pair from the dataset\n",
    "random_index = np.random.randint(len(data_sets.train.images))\n",
    "image_example = data_sets.train.images[random_index]\n",
    "label_example = data_sets.train.labels[random_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the image input is a vector (size: 768 = 28 * 28), representing the grey scale of each pixel of the image. The label is another vector (size: 10), indicating which number the image corresponds to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.00784314,  0.47058827,\n",
       "        0.99215692,  0.12941177,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.34901962,  0.98823535,  0.90980399,  0.09411766,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.08627451,  0.3921569 ,  0.03529412,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.83529419,\n",
       "        0.98823535,  0.51764709,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.21960786,  0.98823535,  0.08235294,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.55686277,  0.98431379,  0.89803928,  0.1254902 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01960784,  0.57254905,  0.98823535,\n",
       "        0.08235294,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.2392157 ,  0.91764712,\n",
       "        0.98823535,  0.53333336,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.57647061,  0.98823535,  0.98823535,  0.08235294,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.07058824,  0.91764712,  0.98823535,  0.80392164,  0.08627451,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.20784315,  0.96862751,  0.98823535,\n",
       "        0.80392164,  0.04313726,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.3137255 ,  0.98823535,\n",
       "        0.97254908,  0.30588236,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04705883,\n",
       "        0.85098046,  0.98823535,  0.8588236 ,  0.08627451,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.2392157 ,  0.97254908,  0.98823535,  0.38039219,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.3921569 ,  0.98823535,  0.98823535,\n",
       "        0.63921571,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.08235294,  0.76078439,  0.98823535,\n",
       "        0.82745105,  0.05490196,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.1137255 ,\n",
       "        0.95294124,  0.98823535,  0.98823535,  0.62352943,  0.43529415,\n",
       "        0.03921569,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.63529414,  0.98823535,  0.95294124,  0.25098041,  0.        ,\n",
       "        0.21176472,  0.43529415,  0.3019608 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.37647063,  0.99215692,  0.99215692,\n",
       "        0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "        0.99215692,  0.99215692,  1.        ,  0.99215692,  0.99215692,\n",
       "        0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "        0.99215692,  0.12941177,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.227451  ,  0.90980399,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.99215692,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
       "        0.98823535,  0.98823535,  0.9450981 ,  0.72941178,  0.09411766,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.12156864,\n",
       "        0.17254902,  0.17254902,  0.17254902,  0.17254902,  0.17254902,\n",
       "        0.17254902,  0.77647066,  0.98823535,  0.99215692,  0.71764708,\n",
       "        0.24313727,  0.17254902,  0.17254902,  0.17254902,  0.17254902,\n",
       "        0.14117648,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.39607847,  0.98039222,\n",
       "        0.98823535,  0.88627458,  0.14509805,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.1254902 ,  0.85490203,  0.98823535,  0.98823535,  0.15294118,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.81568635,  0.98823535,\n",
       "        0.88235301,  0.27058825,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.01176471,\n",
       "        0.53333336,  0.98431379,  0.98039222,  0.47058827,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.21960786,  0.98823535,  0.98823535,\n",
       "        0.5529412 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.21960786,  0.98823535,  0.98823535,  0.38823533,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.21960786,  0.98823535,\n",
       "        0.96862751,  0.21960786,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image is stored as an array like object\n",
    "image_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label is represented in one-hot\n",
    "label_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize the data, we show a graphics of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEICAYAAABMNAHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngy1DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f8c80f5438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the image array into a pixel matrix\n",
    "image_example_pixels = image_example.reshape((28, 28))\n",
    "\n",
    "# Show the image\n",
    "plt.title('Label is {label}'.format(label = label_example))\n",
    "plt.imshow(image_example_pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create a linear model that predicts from image to the number categories. The model needs the image input to predict its category. During trianing, the model also needs the correct label of the image input to it. Therefore, we create two placeholders for the model.\n",
    "\n",
    "Notice that we have to specify the shape and the data type of the tensor. For this tutorial, we use stochastic gradient descent. It means that for each training iteration, we want a small batch of data from the data set (a batch of image-label pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "image_size = 28 * 28\n",
    "category_size = 10\n",
    "\n",
    "# Create a placeholder that has the type of float32 and shape of (batch_size, image_size)\n",
    "images_placeholder = tf.placeholder(tf.float32, shape = (batch_size, image_size))\n",
    "label_placeholder = tf.placeholder(tf.int32, shape = (batch_size, category_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear model can be represented as $y = Wx + b$ where $x$, $y$ are the input vector and output vector of the model respectively. The trainable parameters include $W$ (the weight matrix) and $b$ (the bias vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.zeros(shape = [image_size, category_size])) # The weight matrix\n",
    "biases = tf.Variable(tf.zeros(shape = [category_size]))              # The bias vector\n",
    "output = tf.matmul(images_placeholder, weights) + biases             # The output of the model\n",
    "predict = tf.nn.softmax(output)                                      # Transform the output into a proability distribution over 10 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "After finishing building the model, we can start to train our model. Recall that the learning target for a classification problem is usually the cross entropy between the predicted distribution and true distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the learning target as the cross entropy of the predictions and the labels\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = label_placeholder))\n",
    "\n",
    "# Define a training step to minimize the cross entropy with gradient descent algorithm\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run any op in Tensorflow, we need to first create a session and initialize all the variables defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start training. For each training iteration, we give the model a mini batch of images and labels and perform a training step (performing gradient descent to minimize the cross entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for step in range(1000):\n",
    "    batch_images, batch_labels = data_sets.train.next_batch(batch_size)   # Get a mini batch of images and labels\n",
    "    sess.run(train_step, feed_dict = {images_placeholder : batch_images,  # Perform a training step\n",
    "                                      label_placeholder : batch_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "After 1000 iterations, the model should be well-trained now. We can evaluate our model using the pairs of images and labels from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create ops for prediction accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(label_placeholder, 1), tf.argmax(predict, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Retreive test data\n",
    "test_images = data_sets.test.images[:batch_size]\n",
    "test_labels = data_sets.test.labels[:batch_size]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Prediction Accuracy: \" + str(sess.run(accuracy, feed_dict = {images_placeholder : test_images,\n",
    "                                      label_placeholder : test_labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Usage\n",
    "In this section, we demonstrate a more flexible and complex model to improve the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 2.33\n",
      "Step 100: loss = 0.34\n",
      "Step 200: loss = 0.12\n",
      "Step 300: loss = 0.30\n",
      "Step 400: loss = 0.12\n",
      "Step 500: loss = 0.18\n",
      "Step 600: loss = 0.28\n",
      "Step 700: loss = 0.11\n",
      "Step 800: loss = 0.13\n",
      "Step 900: loss = 0.13\n",
      "Step 1000: loss = 0.08\n",
      "Step 1100: loss = 0.15\n",
      "Step 1200: loss = 0.08\n",
      "Step 1300: loss = 0.04\n",
      "Step 1400: loss = 0.04\n",
      "Step 1500: loss = 0.13\n",
      "Step 1600: loss = 0.05\n",
      "Step 1700: loss = 0.13\n",
      "Step 1800: loss = 0.01\n",
      "Step 1900: loss = 0.06\n",
      "Prediction Accuracy: 0.9691\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "image_size = 28 * 28\n",
    "category_size = 10\n",
    "images_placeholder = tf.placeholder(tf.float32, shape = (None, image_size))   # We can put \"None\" to make the size of the tensor flexible (batch size is variable)\n",
    "label_placeholder = tf.placeholder(tf.int32, shape = (None, category_size)) \n",
    "\n",
    "hidden_units = 128\n",
    "weights1 = tf.Variable(tf.truncated_normal(shape = [image_size, hidden_units], stddev = 0.1))    # The weight matrix from image input to the first hidden layer\n",
    "weights2 = tf.Variable(tf.truncated_normal(shape = [hidden_units, hidden_units], stddev = 0.1))  # The weight matrix from first to second hidden layer\n",
    "weights3 = tf.Variable(tf.truncated_normal(shape = [hidden_units, category_size], stddev = 0.1)) # The weight matrix from second hidden layer to the output\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(shape = [hidden_units]))              # The bias vectors\n",
    "biases2 = tf.Variable(tf.zeros(shape = [hidden_units]))              \n",
    "biases3 = tf.Variable(tf.zeros(shape = [category_size]))              \n",
    "\n",
    "hidden1 = tf.nn.relu(tf.matmul(images_placeholder, weights1) + biases1)\n",
    "hidden2 = tf.nn.relu(tf.matmul(hidden1, weights2) + biases2)\n",
    "output = tf.matmul(hidden2, weights3) + biases3            # The output of the model\n",
    "predict = tf.nn.softmax(output)     \n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = label_placeholder))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for step in range(2000):\n",
    "    batch_images, batch_labels = data_sets.train.next_batch(batch_size)                                    # Get a mini batch of images and labels\n",
    "    _, loss_value = sess.run([train_step, cross_entropy], feed_dict = {images_placeholder : batch_images,  # Perform a training step\n",
    "                                                                       label_placeholder : batch_labels})\n",
    "    \n",
    "    # Display\n",
    "    if step % 100 == 0:\n",
    "        print('Step %d: loss = %.2f' % (step, loss_value))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(label_placeholder, 1), tf.argmax(predict, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Prediction Accuracy: \" + str(sess.run(accuracy, feed_dict = {images_placeholder : data_sets.test.images,\n",
    "                                                                    label_placeholder : data_sets.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*This tutorial is modified from https://www.tensorflow.org/get_started/*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
